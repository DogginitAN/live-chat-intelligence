# Render deployment configuration
# https://docs.render.com/blueprint-spec

services:
  - type: web
    name: live-chat-intelligence
    runtime: python
    plan: starter  # $7/month, includes WebSocket support
    buildCommand: pip install -r requirements.txt
    startCommand: python chat_viz_backend_v2.py
    envVars:
      - key: LLM_PROVIDER
        value: groq
      - key: GROQ_API_KEY
        sync: false  # Set manually in dashboard
      - key: OLLAMA_MODEL
        value: llama-3.1-8b-instant
      - key: WEBSOCKET_PORT
        value: 10000  # Render uses port 10000 for WebSocket
      - key: PORT
        value: 10000
    healthCheckPath: /
